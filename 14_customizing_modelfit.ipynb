{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r-mVh2aCzOMp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnlFyTTpzUbI",
        "outputId": "65c77c99-814a-4099-ba41-568344d808e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train,y_train),(X_test,y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "h0WganYIzxGn"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(-1,28,28,1).astype('float32') /255.0\n",
        "X_test = X_test.reshape(-1,28,28,1).astype('float32') /255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3L9_bd7x0TiE"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential (\n",
        "    [\n",
        "        layers.Input(shape = (28,28,1)),\n",
        "        layers.Conv2D(64,3,padding ='same'),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2D(128,3,padding ='same'),\n",
        "        layers.ReLU(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(10),\n",
        "\n",
        "    ],\n",
        "    name ='model',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "compile: Set up the optimizer and loss function.\n",
        "\n",
        "train_step: Perform a single training step, calculating gradients and updating the model's weights.\n",
        "\n",
        "test_step: Evaluate the model on a batch of test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXBlX1e-2xn5",
        "outputId": "f05f1a5f-92db-4674-c095-627e11913f2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0565 - accuracy: 0.9595\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.0503 - accuracy: 0.9666\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.9674000144004822, 0.0010196175426244736]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class CustomFit(keras.Model):\n",
        "    def __init__(self, model):\n",
        "        super(CustomFit, self).__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def compile(self, optimizer, loss):\n",
        "        super(CustomFit, self).compile()\n",
        "        self.optimizer = optimizer\n",
        "        self.loss = loss\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Caclulate predictions\n",
        "            y_pred = self.model(x, training=True)\n",
        "\n",
        "            # Loss\n",
        "            loss = self.loss(y, y_pred)\n",
        "\n",
        "        # Gradients\n",
        "        training_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, training_vars)\n",
        "\n",
        "        # Step with optimizer\n",
        "        self.optimizer.apply_gradients(zip(gradients, training_vars))\n",
        "        acc_metric.update_state(y, y_pred)\n",
        "\n",
        "        return {\"loss\": loss, \"accuracy\": acc_metric.result()}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_pred = self.model(x, training=False)\n",
        "\n",
        "        # Updates the metrics tracking the loss\n",
        "        loss = self.loss(y, y_pred)\n",
        "\n",
        "        # Update the metrics.\n",
        "        acc_metric.update_state(y, y_pred)\n",
        "        return {\"loss\": loss, \"accuracy\": acc_metric.result()}\n",
        "\n",
        "\n",
        "acc_metric = keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
        "\n",
        "training = CustomFit(model)\n",
        "training.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        ")\n",
        "\n",
        "training.fit(X_train, y_train, batch_size=64, epochs=2)\n",
        "training.evaluate(X_test, y_test, batch_size=64)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
